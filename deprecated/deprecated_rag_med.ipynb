{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# PyMuPDFLoader 을 이용해 PDF 파일 로드\n",
    "pdf_files = [\"alchohol.pdf\", \"cocktail.pdf\"]  # PDF 파일 리스트\n",
    "pages = []\n",
    "for pdf_file in pdf_files:\n",
    "    loader = PyMuPDFLoader(pdf_file)\n",
    "    pages += loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 문서를 문장으로 분리\n",
    "## 청크 크기 500, 각 청크의 50자씩 겹치도록 청크를 나눈다\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# 문장을 임베딩으로 변환하고 벡터 저장소에 저장\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name='BAAI/bge-m3',\n",
    "    #model_kwargs={'device':'cpu'},\n",
    "    model_kwargs={'device':'cuda'},\n",
    "    encode_kwargs={'normalize_embeddings':True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created and persisted\n"
     ]
    }
   ],
   "source": [
    "# 벡터 저장소 생성\n",
    "from langchain.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(docs, embeddings)\n",
    "\n",
    "\n",
    "# 벡터 저장소 경로 설정\n",
    "## 현재 경로에 'vectorstore' 경로 생성\n",
    "vectorstore_path = 'vectorstore'\n",
    "os.makedirs(vectorstore_path, exist_ok=True)\n",
    "\n",
    "# 벡터 저장소 생성 및 저장\n",
    "vectorstore = Chroma.from_documents(docs, embeddings, persist_directory=vectorstore_path)\n",
    "# 벡터스토어 데이터를 디스크에 저장\n",
    "vectorstore.persist()\n",
    "print(\"Vectorstore created and persisted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Ollama 를 이용해 로컬에서 LLM 실행\n",
    "## llama3-ko-instruct 모델 다운로드는 Ollama 사용법 참조\n",
    "model = ChatOllama(model=\"llama3.2:1b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# Prompt 템플릿 생성\n",
    "template = '''As a friendly chatbot, please answer the question as thoroughly and kindly as possible. All answers should be in English:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query (No RAG): What's the impact of COVID-19?\n",
      "Answer (No RAG): The COVID-19 pandemic has had a significant impact on global health, economies, and societies. Here are some key effects:\n",
      "\n",
      "1. **Global spread**: The virus was first detected in Wuhan, China in December 2019, but it quickly spread to other parts of the world, infecting millions of people.\n",
      "2. **Economic disruption**: The pandemic led to widespread lockdowns, travel restrictions, and supply chain disruptions, causing significant economic losses for many countries.\n",
      "3. **Healthcare strain**: The rapid spread of COVID-19 put a huge burden on healthcare systems worldwide, with many hospitals facing shortages of personal protective equipment (PPE), staff, and resources.\n",
      "4. **Social distancing measures**: Governments implemented social distancing measures, such as mask mandates, travel restrictions, and stay-at-home orders, to slow the spread of the virus.\n",
      "5. **Vaccine development**: The pandemic accelerated the development of COVID-19 vaccines, with multiple vaccines being approved for emergency use in many countries.\n",
      "6. **Changes in work patterns**: The pandemic led to a shift towards remote work, with many companies adopting flexible work arrangements to reduce the risk of transmission.\n",
      "7. **Increased focus on mental health**: The pandemic highlighted the importance of mental health support, with many people experiencing anxiety, depression, and other mental health concerns.\n",
      "\n",
      "These are just some of the key impacts of COVID-19. If you'd like more information or have specific questions about a particular aspect of the pandemic, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# RAG 없이 단순 프롬프트 실행\n",
    "simple_prompt = ChatPromptTemplate.from_template('''As a friendly chatbot, please answer the question as thoroughly and kindly as possible. All answers should be in English:\n",
    "\n",
    "Question: {question}\n",
    "''')\n",
    "\n",
    "simple_chain = (\n",
    "    {'question': RunnablePassthrough()}\n",
    "    | simple_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# RAG 없이 실행\n",
    "query = \"What were the social, economic, and public health impacts of increased alcohol consumption during the COVID-19 pandemic, and what policy approaches can effectively address these issues?\"\n",
    "answer_without_rag = simple_chain.invoke(query)\n",
    "\n",
    "print(\"Query (No RAG):\", query)\n",
    "print(\"Answer (No RAG):\", answer_without_rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query (RAG): What's the impact of COVID-19?\n",
      "Answer (RAG): The text discusses how COVID-19 can be seen as an exemplar of our ambivalent relationship with alcohol and its consequences. It highlights two groups that need attention: those already struggling with alcohol dependence, who may find online services more appealing than others who lack technology or privacy.\n",
      "\n",
      "To answer your question directly, the impact of COVID-19 is multifaceted and can be seen in various aspects:\n",
      "\n",
      "1. **Public health**: The pandemic has led to a significant increase in cases of alcohol-related problems, such as binge drinking and excessive consumption.\n",
      "2. **Social and economic impacts**: The shift to online services may have exacerbated existing social issues, like isolation and loneliness, which are often linked to alcohol use.\n",
      "3. **Mental health**: COVID-19 has been linked to increased rates of anxiety, depression, and other mental health concerns, potentially related to the stress and uncertainty caused by the pandemic.\n",
      "\n",
      "These factors highlight the complex relationship between COVID-19 and alcohol consumption, underscoring the need for continued attention and support from various stakeholders.\n"
     ]
    }
   ],
   "source": [
    "# RAG Chain 연결\n",
    "rag_chain = (\n",
    "    {'context': retriever | format_docs, 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Chain 실행\n",
    "answer = rag_chain.invoke(query)\n",
    "\n",
    "print(\"Query (RAG):\", query)\n",
    "print(\"Answer (RAG):\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
